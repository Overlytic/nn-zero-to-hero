{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5a049eb9-6141-4a50-b3ff-0f1725b36d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "16d46cd7-1326-463d-820c-59118c493421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('names.txt').read().splitlines()\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "661d506c-2118-4767-9b69-d61b8d7eaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb5c73-4050-4a51-bc77-155297ae476c",
   "metadata": {},
   "source": [
    "# First try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "018386e0-69b9-454b-9203-88fb53ba4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used 27*27=729 input dimension for input of two characters\n",
    "# doesnt work well though ... try to think why this isnt good. Drops information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d3befe12-0b72-4394-9828-81558332b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "ytoi = {s:i for i,s in enumerate(chars)}\n",
    "ytos = {i:s for s,i in ytoi.items()}\n",
    "charcount=len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "faae9f4f-61ea-469f-a7ec-0a584cc99c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtoi = {}\n",
    "i = 0\n",
    "for ch1 in chars:\n",
    "    for ch2 in chars: \n",
    "        xtoi[(ch1, ch2)] = i\n",
    "        i += 1\n",
    "        \n",
    "xtos = {i:s for s,i in xtoi.items()}\n",
    "xdim = len(xtoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ba4800c4-b99b-456b-93f2-c0fc6d645213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  260179\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix = xtoi[(ch1, ch2)]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append(ix)\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((xdim, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e9b7e472-c94c-438d-b0a7-9a968be6d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', '.'), ('.', 'e'), ('e', 'm'), ('m', 'm'), ('m', 'a'), ('a', '.')]\n",
      "['e', 'm', 'm', 'a', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "# print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([xtos[x.item()] for x in xs[:6]])\n",
    "print([ytos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b5ecdf68-de98-4ca3-80dd-898e97931ce4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7422749996185303\n",
      "3.5306496620178223\n",
      "3.3819174766540527\n",
      "3.2758371829986572\n",
      "3.1978492736816406\n",
      "3.1354622840881348\n",
      "3.082799196243286\n",
      "3.0368664264678955\n",
      "2.995882987976074\n",
      "2.958749294281006\n",
      "2.924757480621338\n",
      "2.8934175968170166\n",
      "2.8643672466278076\n",
      "2.8373255729675293\n",
      "2.8120646476745605\n",
      "2.788397789001465\n",
      "2.7661678791046143\n",
      "2.745241641998291\n",
      "2.725506067276001\n",
      "2.706862449645996\n",
      "2.689223289489746\n",
      "2.6725120544433594\n",
      "2.656658887863159\n",
      "2.6416001319885254\n",
      "2.627277374267578\n",
      "2.613636016845703\n",
      "2.6006274223327637\n",
      "2.5882060527801514\n",
      "2.576331377029419\n",
      "2.5649654865264893\n",
      "2.554074287414551\n",
      "2.543628215789795\n",
      "2.533597946166992\n",
      "2.5239593982696533\n",
      "2.514688491821289\n",
      "2.5057642459869385\n",
      "2.497166872024536\n",
      "2.488878011703491\n",
      "2.4808812141418457\n",
      "2.4731600284576416\n",
      "2.465700149536133\n",
      "2.4584872722625732\n",
      "2.4515087604522705\n",
      "2.4447524547576904\n",
      "2.438206672668457\n",
      "2.4318606853485107\n",
      "2.4257047176361084\n",
      "2.419728994369507\n",
      "2.4139249324798584\n",
      "2.4082834720611572\n",
      "2.4027976989746094\n",
      "2.3974592685699463\n",
      "2.3922622203826904\n",
      "2.387199640274048\n",
      "2.3822648525238037\n",
      "2.377453327178955\n",
      "2.3727593421936035\n",
      "2.3681771755218506\n",
      "2.3637032508850098\n",
      "2.3593320846557617\n",
      "2.355060338973999\n",
      "2.3508834838867188\n",
      "2.3467981815338135\n",
      "2.3428006172180176\n",
      "2.3388876914978027\n",
      "2.3350563049316406\n",
      "2.331303596496582\n",
      "2.3276264667510986\n",
      "2.3240225315093994\n",
      "2.3204891681671143\n",
      "2.317023992538452\n",
      "2.3136250972747803\n",
      "2.3102898597717285\n",
      "2.307016611099243\n",
      "2.303802728652954\n",
      "2.300647020339966\n",
      "2.2975475788116455\n",
      "2.2945024967193604\n",
      "2.2915103435516357\n",
      "2.288569927215576\n",
      "2.2856788635253906\n",
      "2.2828361988067627\n",
      "2.280041217803955\n",
      "2.277291774749756\n",
      "2.2745869159698486\n",
      "2.271925449371338\n",
      "2.269306182861328\n",
      "2.266728162765503\n",
      "2.264190196990967\n",
      "2.2616915702819824\n",
      "2.259230375289917\n",
      "2.2568070888519287\n",
      "2.2544195652008057\n",
      "2.2520673274993896\n",
      "2.2497501373291016\n",
      "2.247466564178467\n",
      "2.245216131210327\n",
      "2.242997407913208\n",
      "2.2408101558685303\n",
      "2.238654136657715\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=xdim).float() # input to the network: one_hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7df6f53c-30a3-4753-a679-29c8e19486af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emracvvaromkxttszpgschuhqvbmxemc.\n",
      "emmxqvydusmasemripdkfbllvkfemhusxnumhtdjixwlu.\n",
      "embw.\n",
      "emhpyucemhqhrxktpdiqslu.\n",
      "emajadkrlqriabwtvscjmhqwtpxemygdwfvnnjcjchwzwjywtogdnppollwtqyhdmwdjuyggluyyyqwvbuytofbcvbmbotdkajlnplpnpjmjmaoodqy.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out=[]\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=xdim).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[ix])\n",
    "        if ix == 0: \n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689ff44-1d41-4934-be49-ceff97f4573e",
   "metadata": {},
   "source": [
    "# Second try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d9a5d-57e6-4325-a1de-8e4150e82b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if this is a trigram model. Not taking order into account here. \n",
    "# a b -> c    and   b a -> c      is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8043d851-09f9-4f03-8bdd-77f41dbd5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "numchars=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "81ea209a-be8a-451e-9293-587d6105ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "00654821-6cb8-4796-b7bb-4c722a07fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "138cbc15-5861-433c-9257-b0268ff2ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  5],\n",
      "        [ 5, 13],\n",
      "        [13, 13],\n",
      "        [13,  1],\n",
      "        [ 0, 15],\n",
      "        [15, 12]])\n",
      "tensor([13, 13,  1,  0, 12,  9])\n",
      "['.e', 'em', 'mm', 'ma', '.o', 'ol']\n",
      "['m', 'm', 'a', '.', 'l', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(xs[:6])\n",
    "print(ys[:6])\n",
    "print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([itos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "641939fe-775e-439b-b5ac-61296d6c6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196113, 54])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=numchars).float()\n",
    "xenc.shape\n",
    "xenc.view(-1, 2*27).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "3028af13-b1e8-44d9-b0a1-55b6c941b633",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2434895038604736\n",
      "2.2434890270233154\n",
      "2.243488311767578\n",
      "2.243487596511841\n",
      "2.2434871196746826\n",
      "2.2434866428375244\n",
      "2.243485927581787\n",
      "2.24348521232605\n",
      "2.2434849739074707\n",
      "2.2434842586517334\n",
      "2.243483781814575\n",
      "2.243483066558838\n",
      "2.2434825897216797\n",
      "2.2434818744659424\n",
      "2.243481159210205\n",
      "2.243480682373047\n",
      "2.2434802055358887\n",
      "2.2434792518615723\n",
      "2.243478775024414\n",
      "2.243478298187256\n",
      "2.2434778213500977\n",
      "2.2434773445129395\n",
      "2.243476629257202\n",
      "2.243475914001465\n",
      "2.2434754371643066\n",
      "2.2434747219085693\n",
      "2.243474245071411\n",
      "2.243473529815674\n",
      "2.2434730529785156\n",
      "2.2434725761413574\n",
      "2.24347186088562\n",
      "2.243471384048462\n",
      "2.2434706687927246\n",
      "2.2434701919555664\n",
      "2.243469715118408\n",
      "2.243468999862671\n",
      "2.2434682846069336\n",
      "2.2434680461883545\n",
      "2.243467330932617\n",
      "2.243466854095459\n",
      "2.2434661388397217\n",
      "2.2434654235839844\n",
      "2.243464946746826\n",
      "2.243464469909668\n",
      "2.2434635162353516\n",
      "2.2434632778167725\n",
      "2.243462562561035\n",
      "2.243462085723877\n",
      "2.2434616088867188\n",
      "2.2434611320495605\n",
      "2.2434604167938232\n",
      "2.243459701538086\n",
      "2.2434592247009277\n",
      "2.2434585094451904\n",
      "2.2434580326080322\n",
      "2.243457317352295\n",
      "2.2434568405151367\n",
      "2.2434563636779785\n",
      "2.2434558868408203\n",
      "2.243455171585083\n",
      "2.243454694747925\n",
      "2.2434539794921875\n",
      "2.2434535026550293\n",
      "2.243453025817871\n",
      "2.243452310562134\n",
      "2.2434515953063965\n",
      "2.2434511184692383\n",
      "2.24345064163208\n",
      "2.2434499263763428\n",
      "2.2434492111206055\n",
      "2.2434487342834473\n",
      "2.243448257446289\n",
      "2.2434475421905518\n",
      "2.2434470653533936\n",
      "2.2434463500976562\n",
      "2.243445634841919\n",
      "2.24344539642334\n",
      "2.2434446811676025\n",
      "2.2434442043304443\n",
      "2.243443489074707\n",
      "2.2434427738189697\n",
      "2.2434422969818115\n",
      "2.2434418201446533\n",
      "2.243441343307495\n",
      "2.243440866470337\n",
      "2.2434399127960205\n",
      "2.2434394359588623\n",
      "2.243438959121704\n",
      "2.243438243865967\n",
      "2.2434377670288086\n",
      "2.2434372901916504\n",
      "2.243436813354492\n",
      "2.243436098098755\n",
      "2.2434356212615967\n",
      "2.2434349060058594\n",
      "2.243434190750122\n",
      "2.243433713912964\n",
      "2.2434332370758057\n",
      "2.2434327602386475\n",
      "2.24343204498291\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=numchars).float() # input to the network: one_hot encoding\n",
    "    logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d9ff9596-ac6d-4f2c-a411-93c588bddf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check reshaping ... \n",
    "# xenc = F.one_hot(torch.tensor([0, 0]), num_classes=3).float()\n",
    "xenc.view(-1, 2*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "831af6c4-3469-4f03-8d1c-7ad49a2ff451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osprgetrumallymarlannavikh.\n",
      "ree.\n",
      "isnerse.\n",
      "ore.\n",
      "sarneve.\n",
      "ah.\n",
      "aim.\n",
      "enikavielah.\n",
      "sh.\n",
      "aia.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    out=[]\n",
    "    ix1 = 0\n",
    "    ix2 = torch.randint(1, 27, (1,), generator=g)\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=numchars).float()\n",
    "        logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[iy])\n",
    "        if iy == 0: \n",
    "            break\n",
    "            \n",
    "        ix1 = ix2\n",
    "        ix2 = iy\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
