{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5a049eb9-6141-4a50-b3ff-0f1725b36d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "16d46cd7-1326-463d-820c-59118c493421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('names.txt').read().splitlines()\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "661d506c-2118-4767-9b69-d61b8d7eaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb5c73-4050-4a51-bc77-155297ae476c",
   "metadata": {},
   "source": [
    "# First try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "018386e0-69b9-454b-9203-88fb53ba4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used 27*27=729 input dimension for input of two characters\n",
    "# doesnt work well though ... try to think why this isnt good. Drops information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d3befe12-0b72-4394-9828-81558332b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "ytoi = {s:i for i,s in enumerate(chars)}\n",
    "ytos = {i:s for s,i in ytoi.items()}\n",
    "charcount=len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "faae9f4f-61ea-469f-a7ec-0a584cc99c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtoi = {}\n",
    "i = 0\n",
    "for ch1 in chars:\n",
    "    for ch2 in chars: \n",
    "        xtoi[(ch1, ch2)] = i\n",
    "        i += 1\n",
    "        \n",
    "xtos = {i:s for s,i in xtoi.items()}\n",
    "xdim = len(xtoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ba4800c4-b99b-456b-93f2-c0fc6d645213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  260179\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix = xtoi[(ch1, ch2)]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append(ix)\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((xdim, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e9b7e472-c94c-438d-b0a7-9a968be6d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', '.'), ('.', 'e'), ('e', 'm'), ('m', 'm'), ('m', 'a'), ('a', '.')]\n",
      "['e', 'm', 'm', 'a', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "# print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([xtos[x.item()] for x in xs[:6]])\n",
    "print([ytos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b5ecdf68-de98-4ca3-80dd-898e97931ce4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7422749996185303\n",
      "3.5306496620178223\n",
      "3.3819174766540527\n",
      "3.2758371829986572\n",
      "3.1978492736816406\n",
      "3.1354622840881348\n",
      "3.082799196243286\n",
      "3.0368664264678955\n",
      "2.995882987976074\n",
      "2.958749294281006\n",
      "2.924757480621338\n",
      "2.8934175968170166\n",
      "2.8643672466278076\n",
      "2.8373255729675293\n",
      "2.8120646476745605\n",
      "2.788397789001465\n",
      "2.7661678791046143\n",
      "2.745241641998291\n",
      "2.725506067276001\n",
      "2.706862449645996\n",
      "2.689223289489746\n",
      "2.6725120544433594\n",
      "2.656658887863159\n",
      "2.6416001319885254\n",
      "2.627277374267578\n",
      "2.613636016845703\n",
      "2.6006274223327637\n",
      "2.5882060527801514\n",
      "2.576331377029419\n",
      "2.5649654865264893\n",
      "2.554074287414551\n",
      "2.543628215789795\n",
      "2.533597946166992\n",
      "2.5239593982696533\n",
      "2.514688491821289\n",
      "2.5057642459869385\n",
      "2.497166872024536\n",
      "2.488878011703491\n",
      "2.4808812141418457\n",
      "2.4731600284576416\n",
      "2.465700149536133\n",
      "2.4584872722625732\n",
      "2.4515087604522705\n",
      "2.4447524547576904\n",
      "2.438206672668457\n",
      "2.4318606853485107\n",
      "2.4257047176361084\n",
      "2.419728994369507\n",
      "2.4139249324798584\n",
      "2.4082834720611572\n",
      "2.4027976989746094\n",
      "2.3974592685699463\n",
      "2.3922622203826904\n",
      "2.387199640274048\n",
      "2.3822648525238037\n",
      "2.377453327178955\n",
      "2.3727593421936035\n",
      "2.3681771755218506\n",
      "2.3637032508850098\n",
      "2.3593320846557617\n",
      "2.355060338973999\n",
      "2.3508834838867188\n",
      "2.3467981815338135\n",
      "2.3428006172180176\n",
      "2.3388876914978027\n",
      "2.3350563049316406\n",
      "2.331303596496582\n",
      "2.3276264667510986\n",
      "2.3240225315093994\n",
      "2.3204891681671143\n",
      "2.317023992538452\n",
      "2.3136250972747803\n",
      "2.3102898597717285\n",
      "2.307016611099243\n",
      "2.303802728652954\n",
      "2.300647020339966\n",
      "2.2975475788116455\n",
      "2.2945024967193604\n",
      "2.2915103435516357\n",
      "2.288569927215576\n",
      "2.2856788635253906\n",
      "2.2828361988067627\n",
      "2.280041217803955\n",
      "2.277291774749756\n",
      "2.2745869159698486\n",
      "2.271925449371338\n",
      "2.269306182861328\n",
      "2.266728162765503\n",
      "2.264190196990967\n",
      "2.2616915702819824\n",
      "2.259230375289917\n",
      "2.2568070888519287\n",
      "2.2544195652008057\n",
      "2.2520673274993896\n",
      "2.2497501373291016\n",
      "2.247466564178467\n",
      "2.245216131210327\n",
      "2.242997407913208\n",
      "2.2408101558685303\n",
      "2.238654136657715\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=xdim).float() # input to the network: one_hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7df6f53c-30a3-4753-a679-29c8e19486af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emracvvaromkxttszpgschuhqvbmxemc.\n",
      "emmxqvydusmasemripdkfbllvkfemhusxnumhtdjixwlu.\n",
      "embw.\n",
      "emhpyucemhqhrxktpdiqslu.\n",
      "emajadkrlqriabwtvscjmhqwtpxemygdwfvnnjcjchwzwjywtogdnppollwtqyhdmwdjuyggluyyyqwvbuytofbcvbmbotdkajlnplpnpjmjmaoodqy.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out=[]\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=xdim).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[ix])\n",
    "        if ix == 0: \n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689ff44-1d41-4934-be49-ceff97f4573e",
   "metadata": {},
   "source": [
    "# Second try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d9a5d-57e6-4325-a1de-8e4150e82b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if this is a trigram model. Not taking order into account here. \n",
    "# a b -> c    and   b a -> c      is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8043d851-09f9-4f03-8bdd-77f41dbd5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "numchars=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "81ea209a-be8a-451e-9293-587d6105ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "00654821-6cb8-4796-b7bb-4c722a07fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  260179\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "138cbc15-5861-433c-9257-b0268ff2ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 0,  5],\n",
      "        [ 5, 13],\n",
      "        [13, 13],\n",
      "        [13,  1],\n",
      "        [ 1,  0]])\n",
      "tensor([ 5, 13, 13,  1,  0,  0])\n",
      "['..', '.e', 'em', 'mm', 'ma', 'a.']\n",
      "['e', 'm', 'm', 'a', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(xs[:6])\n",
    "print(ys[:6])\n",
    "print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([itos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d9ff9596-ac6d-4f2c-a411-93c588bddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reshaping ... \n",
    "#xenc = F.one_hot(torch.tensor([0, 0]), num_classes=3).float()\n",
    "#xenc.view(-1, 2*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "3028af13-b1e8-44d9-b0a1-55b6c941b633",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.062056541442871\n",
      "3.3332533836364746\n",
      "3.143059492111206\n",
      "2.8806777000427246\n",
      "2.594698190689087\n",
      "2.482520580291748\n",
      "2.4328184127807617\n",
      "2.394172430038452\n",
      "2.3659307956695557\n",
      "2.3400487899780273\n",
      "2.325944662094116\n",
      "2.3032467365264893\n",
      "2.300849437713623\n",
      "2.273113965988159\n",
      "2.274749279022217\n",
      "2.2484052181243896\n",
      "2.25191068649292\n",
      "2.2289681434631348\n",
      "2.2345147132873535\n",
      "2.2132339477539062\n",
      "2.220303535461426\n",
      "2.2001843452453613\n",
      "2.208400011062622\n",
      "2.189166784286499\n",
      "2.1982812881469727\n",
      "2.17972731590271\n",
      "2.1895668506622314\n",
      "2.1715431213378906\n",
      "2.181980609893799\n",
      "2.1643781661987305\n",
      "2.17531681060791\n",
      "2.158053159713745\n",
      "2.1694176197052\n",
      "2.1524293422698975\n",
      "2.1641595363616943\n",
      "2.147397756576538\n",
      "2.159444570541382\n",
      "2.1428709030151367\n",
      "2.155193567276001\n",
      "2.1387779712677\n",
      "2.1513431072235107\n",
      "2.1350605487823486\n",
      "2.1478404998779297\n",
      "2.131671667098999\n",
      "2.144641876220703\n",
      "2.128570556640625\n",
      "2.1417105197906494\n",
      "2.1257236003875732\n",
      "2.1390159130096436\n",
      "2.1231019496917725\n",
      "2.136530637741089\n",
      "2.1206812858581543\n",
      "2.13423228263855\n",
      "2.118440628051758\n",
      "2.13210129737854\n",
      "2.1163601875305176\n",
      "2.1301207542419434\n",
      "2.1144254207611084\n",
      "2.128274917602539\n",
      "2.1126210689544678\n",
      "2.126551389694214\n",
      "2.1109349727630615\n",
      "2.124938488006592\n",
      "2.109356164932251\n",
      "2.123425245285034\n",
      "2.107875108718872\n",
      "2.122004270553589\n",
      "2.106482982635498\n",
      "2.120666027069092\n",
      "2.1051719188690186\n",
      "2.1194043159484863\n",
      "2.103935480117798\n",
      "2.1182122230529785\n",
      "2.1027672290802\n",
      "2.11708402633667\n",
      "2.1016616821289062\n",
      "2.1160154342651367\n",
      "2.100613832473755\n",
      "2.1150012016296387\n",
      "2.0996196269989014\n",
      "2.114036798477173\n",
      "2.0986742973327637\n",
      "2.113119602203369\n",
      "2.0977752208709717\n",
      "2.112245798110962\n",
      "2.0969181060791016\n",
      "2.111412286758423\n",
      "2.0961008071899414\n",
      "2.1106162071228027\n",
      "2.095320463180542\n",
      "2.1098551750183105\n",
      "2.094573736190796\n",
      "2.1091268062591553\n",
      "2.0938596725463867\n",
      "2.108429193496704\n",
      "2.093175172805786\n",
      "2.107759952545166\n",
      "2.0925192832946777\n",
      "2.1071181297302246\n",
      "2.0918893814086914\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=numchars).float() # input to the network: one_hot encoding\n",
    "    logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "831af6c4-3469-4f03-8d1c-7ad49a2ff451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orivadurtih.\n",
      "isoyddraisemiabrada.\n",
      "ushise.\n",
      "ore.\n",
      "sarndve.\n",
      "ee.\n",
      "ekh.\n",
      "ingikon.\n",
      "ir.\n",
      "yres.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    out=[]\n",
    "    ix1 = 0\n",
    "    ix2 = torch.randint(1, 27, (1,), generator=g)\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=numchars).float()\n",
    "        logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[iy])\n",
    "        if iy == 0: \n",
    "            break\n",
    "            \n",
    "        ix1 = ix2\n",
    "        ix2 = iy\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
