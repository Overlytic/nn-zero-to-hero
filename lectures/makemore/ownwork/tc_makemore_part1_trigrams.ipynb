{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5a049eb9-6141-4a50-b3ff-0f1725b36d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "16d46cd7-1326-463d-820c-59118c493421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('names.txt').read().splitlines()\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "661d506c-2118-4767-9b69-d61b8d7eaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb5c73-4050-4a51-bc77-155297ae476c",
   "metadata": {},
   "source": [
    "# First try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "018386e0-69b9-454b-9203-88fb53ba4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used 27*27=729 input dimension for input of two characters\n",
    "# doesnt work well though ... try to think why this isnt good. Drops information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d3befe12-0b72-4394-9828-81558332b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "ytoi = {s:i for i,s in enumerate(chars)}\n",
    "ytos = {i:s for s,i in ytoi.items()}\n",
    "charcount=len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "faae9f4f-61ea-469f-a7ec-0a584cc99c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtoi = {}\n",
    "i = 0\n",
    "for ch1 in chars:\n",
    "    for ch2 in chars: \n",
    "        xtoi[(ch1, ch2)] = i\n",
    "        i += 1\n",
    "        \n",
    "xtos = {i:s for s,i in xtoi.items()}\n",
    "xdim = len(xtoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ba4800c4-b99b-456b-93f2-c0fc6d645213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  260179\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix = xtoi[(ch1, ch2)]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append(ix)\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((xdim, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e9b7e472-c94c-438d-b0a7-9a968be6d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', '.'), ('.', 'e'), ('e', 'm'), ('m', 'm'), ('m', 'a'), ('a', '.')]\n",
      "['e', 'm', 'm', 'a', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "# print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([xtos[x.item()] for x in xs[:6]])\n",
    "print([ytos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b5ecdf68-de98-4ca3-80dd-898e97931ce4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7422749996185303\n",
      "3.5306496620178223\n",
      "3.3819174766540527\n",
      "3.2758371829986572\n",
      "3.1978492736816406\n",
      "3.1354622840881348\n",
      "3.082799196243286\n",
      "3.0368664264678955\n",
      "2.995882987976074\n",
      "2.958749294281006\n",
      "2.924757480621338\n",
      "2.8934175968170166\n",
      "2.8643672466278076\n",
      "2.8373255729675293\n",
      "2.8120646476745605\n",
      "2.788397789001465\n",
      "2.7661678791046143\n",
      "2.745241641998291\n",
      "2.725506067276001\n",
      "2.706862449645996\n",
      "2.689223289489746\n",
      "2.6725120544433594\n",
      "2.656658887863159\n",
      "2.6416001319885254\n",
      "2.627277374267578\n",
      "2.613636016845703\n",
      "2.6006274223327637\n",
      "2.5882060527801514\n",
      "2.576331377029419\n",
      "2.5649654865264893\n",
      "2.554074287414551\n",
      "2.543628215789795\n",
      "2.533597946166992\n",
      "2.5239593982696533\n",
      "2.514688491821289\n",
      "2.5057642459869385\n",
      "2.497166872024536\n",
      "2.488878011703491\n",
      "2.4808812141418457\n",
      "2.4731600284576416\n",
      "2.465700149536133\n",
      "2.4584872722625732\n",
      "2.4515087604522705\n",
      "2.4447524547576904\n",
      "2.438206672668457\n",
      "2.4318606853485107\n",
      "2.4257047176361084\n",
      "2.419728994369507\n",
      "2.4139249324798584\n",
      "2.4082834720611572\n",
      "2.4027976989746094\n",
      "2.3974592685699463\n",
      "2.3922622203826904\n",
      "2.387199640274048\n",
      "2.3822648525238037\n",
      "2.377453327178955\n",
      "2.3727593421936035\n",
      "2.3681771755218506\n",
      "2.3637032508850098\n",
      "2.3593320846557617\n",
      "2.355060338973999\n",
      "2.3508834838867188\n",
      "2.3467981815338135\n",
      "2.3428006172180176\n",
      "2.3388876914978027\n",
      "2.3350563049316406\n",
      "2.331303596496582\n",
      "2.3276264667510986\n",
      "2.3240225315093994\n",
      "2.3204891681671143\n",
      "2.317023992538452\n",
      "2.3136250972747803\n",
      "2.3102898597717285\n",
      "2.307016611099243\n",
      "2.303802728652954\n",
      "2.300647020339966\n",
      "2.2975475788116455\n",
      "2.2945024967193604\n",
      "2.2915103435516357\n",
      "2.288569927215576\n",
      "2.2856788635253906\n",
      "2.2828361988067627\n",
      "2.280041217803955\n",
      "2.277291774749756\n",
      "2.2745869159698486\n",
      "2.271925449371338\n",
      "2.269306182861328\n",
      "2.266728162765503\n",
      "2.264190196990967\n",
      "2.2616915702819824\n",
      "2.259230375289917\n",
      "2.2568070888519287\n",
      "2.2544195652008057\n",
      "2.2520673274993896\n",
      "2.2497501373291016\n",
      "2.247466564178467\n",
      "2.245216131210327\n",
      "2.242997407913208\n",
      "2.2408101558685303\n",
      "2.238654136657715\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=xdim).float() # input to the network: one_hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7df6f53c-30a3-4753-a679-29c8e19486af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emracvvaromkxttszpgschuhqvbmxemc.\n",
      "emmxqvydusmasemripdkfbllvkfemhusxnumhtdjixwlu.\n",
      "embw.\n",
      "emhpyucemhqhrxktpdiqslu.\n",
      "emajadkrlqriabwtvscjmhqwtpxemygdwfvnnjcjchwzwjywtogdnppollwtqyhdmwdjuyggluyyyqwvbuytofbcvbmbotdkajlnplpnpjmjmaoodqy.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out=[]\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=xdim).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[ix])\n",
    "        if ix == 0: \n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689ff44-1d41-4934-be49-ceff97f4573e",
   "metadata": {},
   "source": [
    "# Second try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d9a5d-57e6-4325-a1de-8e4150e82b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if this is a trigram model. Not taking order into account here. \n",
    "# a b -> c    and   b a -> c      is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8043d851-09f9-4f03-8bdd-77f41dbd5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "numchars=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "81ea209a-be8a-451e-9293-587d6105ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "00654821-6cb8-4796-b7bb-4c722a07fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.']   # 2 start tokens for trigram. Only 1 end token needed.\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "138cbc15-5861-433c-9257-b0268ff2ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 0,  5],\n",
      "        [ 5, 13],\n",
      "        [13, 13],\n",
      "        [13,  1],\n",
      "        [ 0,  0]])\n",
      "tensor([ 5, 13, 13,  1,  0, 15])\n",
      "['..', '.e', 'em', 'mm', 'ma', '..']\n",
      "['e', 'm', 'm', 'a', '.', 'o']\n"
     ]
    }
   ],
   "source": [
    "print(xs[:6])\n",
    "print(ys[:6])\n",
    "print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([itos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d9ff9596-ac6d-4f2c-a411-93c588bddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reshaping ... \n",
    "#xenc = F.one_hot(torch.tensor([0, 0]), num_classes=3).float()\n",
    "#xenc.view(-1, 2*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3028af13-b1e8-44d9-b0a1-55b6c941b633",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3706207275390625\n",
      "2.3684327602386475\n",
      "2.3665053844451904\n",
      "2.3648037910461426\n",
      "2.3632960319519043\n",
      "2.361957311630249\n",
      "2.3607656955718994\n",
      "2.3597023487091064\n",
      "2.358751058578491\n",
      "2.3578991889953613\n",
      "2.357133626937866\n",
      "2.3564453125\n",
      "2.3558244705200195\n",
      "2.3552639484405518\n",
      "2.3547568321228027\n",
      "2.354297637939453\n",
      "2.3538804054260254\n",
      "2.3535008430480957\n",
      "2.3531551361083984\n",
      "2.352839946746826\n",
      "2.3525519371032715\n",
      "2.352288007736206\n",
      "2.352046489715576\n",
      "2.3518245220184326\n",
      "2.3516201972961426\n",
      "2.3514323234558105\n",
      "2.3512589931488037\n",
      "2.3510985374450684\n",
      "2.350950241088867\n",
      "2.3508129119873047\n",
      "2.3506855964660645\n",
      "2.3505666255950928\n",
      "2.3504562377929688\n",
      "2.3503530025482178\n",
      "2.350257158279419\n",
      "2.3501670360565186\n",
      "2.3500823974609375\n",
      "2.350003480911255\n",
      "2.349928855895996\n",
      "2.3498589992523193\n",
      "2.349792957305908\n",
      "2.3497304916381836\n",
      "2.3496718406677246\n",
      "2.349616050720215\n",
      "2.3495633602142334\n",
      "2.349513530731201\n",
      "2.349465847015381\n",
      "2.3494205474853516\n",
      "2.3493776321411133\n",
      "2.349336624145508\n",
      "2.349297046661377\n",
      "2.349259853363037\n",
      "2.349224090576172\n",
      "2.3491897583007812\n",
      "2.3491568565368652\n",
      "2.3491251468658447\n",
      "2.349095106124878\n",
      "2.3490657806396484\n",
      "2.3490374088287354\n",
      "2.349010705947876\n",
      "2.348984479904175\n",
      "2.3489596843719482\n",
      "2.34893536567688\n",
      "2.348912000656128\n",
      "2.3488893508911133\n",
      "2.348867654800415\n",
      "2.348846197128296\n",
      "2.3488259315490723\n",
      "2.3488059043884277\n",
      "2.3487865924835205\n",
      "2.3487682342529297\n",
      "2.348749876022339\n",
      "2.3487322330474854\n",
      "2.348715305328369\n",
      "2.348698854446411\n",
      "2.348682403564453\n",
      "2.3486671447753906\n",
      "2.348651647567749\n",
      "2.3486366271972656\n",
      "2.3486223220825195\n",
      "2.3486084938049316\n",
      "2.3485946655273438\n",
      "2.348581314086914\n",
      "2.3485682010650635\n",
      "2.348555326461792\n",
      "2.348543167114258\n",
      "2.3485310077667236\n",
      "2.3485193252563477\n",
      "2.3485076427459717\n",
      "2.348496437072754\n",
      "2.3484854698181152\n",
      "2.3484747409820557\n",
      "2.348464250564575\n",
      "2.348453998565674\n",
      "2.3484439849853516\n",
      "2.3484339714050293\n",
      "2.3484244346618652\n",
      "2.3484151363372803\n",
      "2.3484060764312744\n",
      "2.3483970165252686\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=numchars).float() # input to the network: one_hot encoding\n",
    "    logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "831af6c4-3469-4f03-8d1c-7ad49a2ff451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "ays.\n",
      "merhurroydco.\n",
      "konamaloe.\n",
      "caneithizarie.\n",
      "ok.\n",
      "ondalaek.\n",
      "shalekirierielah.\n",
      "yshi.\n",
      "haat.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    out=[]\n",
    "    ix1 = 0\n",
    "    ix2 = 0\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=numchars).float()\n",
    "        logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[iy])\n",
    "        if iy == 0: \n",
    "            break\n",
    "            \n",
    "        ix1 = ix2\n",
    "        ix2 = iy\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f227dc-eb7f-4f20-bfea-64bd784544c9",
   "metadata": {},
   "source": [
    "# Third try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "54ffe1a5-b6d5-4fea-b4c5-23fab71d9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking order into account ... \n",
    "# a b -> c    and   b a -> c      are note the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "3931b05e-395b-4b99-8d94-0266d84298c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "numchars=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f6db487e-233f-4a68-a016-576f01cd8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtoi = {}\n",
    "i = 0\n",
    "for ch1 in chars:\n",
    "    for ch2 in chars: \n",
    "        xtoi[(ch1, ch2)] = i\n",
    "        i += 1\n",
    "        \n",
    "xtos = {i:s for s,i in xtoi.items()}\n",
    "xdim = len(xtoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "c9e2166c-7e02-4033-a555-211200c8d971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.']   # 2 start tokens for trigram. Only 1 end token needed.\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27,27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "b47db723-1232-48c3-9ea4-f09eb91b94a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 0,  5],\n",
      "        [ 5, 13],\n",
      "        [13, 13],\n",
      "        [13,  1],\n",
      "        [ 0,  0]])\n",
      "tensor([ 5, 13, 13,  1,  0, 15])\n",
      "['..', '.e', 'em', 'mm', 'ma', '..']\n",
      "['e', 'm', 'm', 'a', '.', 'o']\n"
     ]
    }
   ],
   "source": [
    "print(xs[:6])\n",
    "print(ys[:6])\n",
    "print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([itos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "48695395-e4d9-4884-9a18-213a7d2f5271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0, 0])\n",
      "1 tensor([0, 5])\n",
      "2 tensor([ 5, 13])\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(xs[:3]):\n",
    "    print(i, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "f4cf193b-465a-4fb3-b5be-44a974bcf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_2d(data, num_classes=27):\n",
    "    rows = data.shape[0]\n",
    "    xenc = torch.zeros(rows, num_classes,num_classes).float()\n",
    "\n",
    "    for i,row in enumerate(data):\n",
    "        col1 = row[0].item()\n",
    "        col2 = row[1].item()\n",
    "        xenc[i, col1, col2] += 1.0\n",
    "        \n",
    "    return xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "1afeda44-da70-46bc-954e-df88cb56ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "8784ad38-1f7d-4d97-b100-9a9650e11b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "39decd84-30e8-4613-857a-9806c5ce3878",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.350231409072876\n",
      "2.349199056625366\n",
      "2.348179817199707\n",
      "2.3471734523773193\n",
      "2.3461804389953613\n",
      "2.3451998233795166\n",
      "2.344231605529785\n",
      "2.343275308609009\n",
      "2.3423309326171875\n",
      "2.341398239135742\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "xenc = one_hot_2d(xs, num_classes=27)\n",
    "\n",
    "for k in range(10):\n",
    "    # forward pass\n",
    "    #xenc = F.one_hot(xs, num_classes=27*27).float() # input to the network: one_hot encoding\n",
    "    logits = xenc.view(-1, 27*27) @ W.view(27*27, -1) # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -100 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "d824f81e-1f05-48ff-a4d3-721cdca06ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mir.\n",
      "axx.\n",
      "mereyannyabraisemmaloah.\n",
      "aqorwgtzarle.\n",
      "oderaleice.\n",
      "dmne.\n",
      "deoosesona.\n",
      "elyn.\n",
      "r.\n",
      "gagv.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    out=[]\n",
    "    ix1 = 0\n",
    "    ix2 = 0\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        # xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27*27).float()\n",
    "        xenc = one_hot_2d(torch.tensor([[ix1, ix2]]), num_classes=27)\n",
    "        logits = xenc.view(-1, 27*27) @ W.view(27*27, -1) # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[iy])\n",
    "        if iy == 0: \n",
    "            break\n",
    "            \n",
    "        ix1 = ix2\n",
    "        ix2 = iy\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
