{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5a049eb9-6141-4a50-b3ff-0f1725b36d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "16d46cd7-1326-463d-820c-59118c493421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('names.txt').read().splitlines()\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "661d506c-2118-4767-9b69-d61b8d7eaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb5c73-4050-4a51-bc77-155297ae476c",
   "metadata": {},
   "source": [
    "# First try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "018386e0-69b9-454b-9203-88fb53ba4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used 27*27=729 input dimension for input of two characters\n",
    "# doesnt work well though ... try to think why this isnt good. Drops information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d3befe12-0b72-4394-9828-81558332b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "ytoi = {s:i for i,s in enumerate(chars)}\n",
    "ytos = {i:s for s,i in ytoi.items()}\n",
    "charcount=len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "faae9f4f-61ea-469f-a7ec-0a584cc99c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtoi = {}\n",
    "i = 0\n",
    "for ch1 in chars:\n",
    "    for ch2 in chars: \n",
    "        xtoi[(ch1, ch2)] = i\n",
    "        i += 1\n",
    "        \n",
    "xtos = {i:s for s,i in xtoi.items()}\n",
    "xdim = len(xtoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ba4800c4-b99b-456b-93f2-c0fc6d645213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  260179\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + ['.'] + list(w) + ['.'] + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix = xtoi[(ch1, ch2)]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append(ix)\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((xdim, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e9b7e472-c94c-438d-b0a7-9a968be6d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', '.'), ('.', 'e'), ('e', 'm'), ('m', 'm'), ('m', 'a'), ('a', '.')]\n",
      "['e', 'm', 'm', 'a', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "# print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([xtos[x.item()] for x in xs[:6]])\n",
    "print([ytos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b5ecdf68-de98-4ca3-80dd-898e97931ce4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7422749996185303\n",
      "3.5306496620178223\n",
      "3.3819174766540527\n",
      "3.2758371829986572\n",
      "3.1978492736816406\n",
      "3.1354622840881348\n",
      "3.082799196243286\n",
      "3.0368664264678955\n",
      "2.995882987976074\n",
      "2.958749294281006\n",
      "2.924757480621338\n",
      "2.8934175968170166\n",
      "2.8643672466278076\n",
      "2.8373255729675293\n",
      "2.8120646476745605\n",
      "2.788397789001465\n",
      "2.7661678791046143\n",
      "2.745241641998291\n",
      "2.725506067276001\n",
      "2.706862449645996\n",
      "2.689223289489746\n",
      "2.6725120544433594\n",
      "2.656658887863159\n",
      "2.6416001319885254\n",
      "2.627277374267578\n",
      "2.613636016845703\n",
      "2.6006274223327637\n",
      "2.5882060527801514\n",
      "2.576331377029419\n",
      "2.5649654865264893\n",
      "2.554074287414551\n",
      "2.543628215789795\n",
      "2.533597946166992\n",
      "2.5239593982696533\n",
      "2.514688491821289\n",
      "2.5057642459869385\n",
      "2.497166872024536\n",
      "2.488878011703491\n",
      "2.4808812141418457\n",
      "2.4731600284576416\n",
      "2.465700149536133\n",
      "2.4584872722625732\n",
      "2.4515087604522705\n",
      "2.4447524547576904\n",
      "2.438206672668457\n",
      "2.4318606853485107\n",
      "2.4257047176361084\n",
      "2.419728994369507\n",
      "2.4139249324798584\n",
      "2.4082834720611572\n",
      "2.4027976989746094\n",
      "2.3974592685699463\n",
      "2.3922622203826904\n",
      "2.387199640274048\n",
      "2.3822648525238037\n",
      "2.377453327178955\n",
      "2.3727593421936035\n",
      "2.3681771755218506\n",
      "2.3637032508850098\n",
      "2.3593320846557617\n",
      "2.355060338973999\n",
      "2.3508834838867188\n",
      "2.3467981815338135\n",
      "2.3428006172180176\n",
      "2.3388876914978027\n",
      "2.3350563049316406\n",
      "2.331303596496582\n",
      "2.3276264667510986\n",
      "2.3240225315093994\n",
      "2.3204891681671143\n",
      "2.317023992538452\n",
      "2.3136250972747803\n",
      "2.3102898597717285\n",
      "2.307016611099243\n",
      "2.303802728652954\n",
      "2.300647020339966\n",
      "2.2975475788116455\n",
      "2.2945024967193604\n",
      "2.2915103435516357\n",
      "2.288569927215576\n",
      "2.2856788635253906\n",
      "2.2828361988067627\n",
      "2.280041217803955\n",
      "2.277291774749756\n",
      "2.2745869159698486\n",
      "2.271925449371338\n",
      "2.269306182861328\n",
      "2.266728162765503\n",
      "2.264190196990967\n",
      "2.2616915702819824\n",
      "2.259230375289917\n",
      "2.2568070888519287\n",
      "2.2544195652008057\n",
      "2.2520673274993896\n",
      "2.2497501373291016\n",
      "2.247466564178467\n",
      "2.245216131210327\n",
      "2.242997407913208\n",
      "2.2408101558685303\n",
      "2.238654136657715\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=xdim).float() # input to the network: one_hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7df6f53c-30a3-4753-a679-29c8e19486af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emracvvaromkxttszpgschuhqvbmxemc.\n",
      "emmxqvydusmasemripdkfbllvkfemhusxnumhtdjixwlu.\n",
      "embw.\n",
      "emhpyucemhqhrxktpdiqslu.\n",
      "emajadkrlqriabwtvscjmhqwtpxemygdwfvnnjcjchwzwjywtogdnppollwtqyhdmwdjuyggluyyyqwvbuytofbcvbmbotdkajlnplpnpjmjmaoodqy.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out=[]\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=xdim).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[ix])\n",
    "        if ix == 0: \n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689ff44-1d41-4934-be49-ceff97f4573e",
   "metadata": {},
   "source": [
    "# Second try for trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d9a5d-57e6-4325-a1de-8e4150e82b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure if this is a trigram model. Not taking order into account here. \n",
    "# a b -> c    and   b a -> c      is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8043d851-09f9-4f03-8bdd-77f41dbd5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list({ch for w in data for ch in w}))\n",
    "chars = ['.'] + chars\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "numchars=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "81ea209a-be8a-451e-9293-587d6105ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "00654821-6cb8-4796-b7bb-4c722a07fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "# build a trigram model\n",
    "\n",
    "# create the training set of bigrams\n",
    "xs, ys = [], []\n",
    "for w in data:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        iy = ytoi[ch3]\n",
    "        xs.append((ix1, ix2))\n",
    "        ys.append(iy)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.shape[0]\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# randomly initialise 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "138cbc15-5861-433c-9257-b0268ff2ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  5],\n",
      "        [ 5, 13],\n",
      "        [13, 13],\n",
      "        [13,  1],\n",
      "        [ 0, 15],\n",
      "        [15, 12]])\n",
      "tensor([13, 13,  1,  0, 12,  9])\n",
      "['.e', 'em', 'mm', 'ma', '.o', 'ol']\n",
      "['m', 'm', 'a', '.', 'l', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(xs[:6])\n",
    "print(ys[:6])\n",
    "print([itos[x[0].item()] + itos[x[1].item()] for x in xs[:6]])\n",
    "print([itos[y.item()] for y in ys[:6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "d9ff9596-ac6d-4f2c-a411-93c588bddf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reshaping ... \n",
    "#xenc = F.one_hot(torch.tensor([0, 0]), num_classes=3).float()\n",
    "#xenc.view(-1, 2*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "3028af13-b1e8-44d9-b0a1-55b6c941b633",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.243431329727173\n",
      "2.2434310913085938\n",
      "2.2434303760528564\n",
      "2.2434298992156982\n",
      "2.24342942237854\n",
      "2.2434284687042236\n",
      "2.2434279918670654\n",
      "2.2434275150299072\n",
      "2.243427038192749\n",
      "2.2434263229370117\n",
      "2.2434256076812744\n",
      "2.243425130844116\n",
      "2.243424654006958\n",
      "2.2434241771698\n",
      "2.2434234619140625\n",
      "2.2434229850769043\n",
      "2.243422269821167\n",
      "2.243421792984009\n",
      "2.2434213161468506\n",
      "2.2434206008911133\n",
      "2.243420124053955\n",
      "2.2434194087982178\n",
      "2.2434189319610596\n",
      "2.2434182167053223\n",
      "2.243417739868164\n",
      "2.2434170246124268\n",
      "2.2434163093566895\n",
      "2.2434158325195312\n",
      "2.243415355682373\n",
      "2.243414878845215\n",
      "2.2434141635894775\n",
      "2.2434139251708984\n",
      "2.243412971496582\n",
      "2.243412494659424\n",
      "2.2434120178222656\n",
      "2.2434113025665283\n",
      "2.24341082572937\n",
      "2.243410348892212\n",
      "2.2434096336364746\n",
      "2.2434091567993164\n",
      "2.243408441543579\n",
      "2.243408203125\n",
      "2.2434074878692627\n",
      "2.2434067726135254\n",
      "2.243406295776367\n",
      "2.243405818939209\n",
      "2.2434051036834717\n",
      "2.2434043884277344\n",
      "2.243403911590576\n",
      "2.243403434753418\n",
      "2.2434027194976807\n",
      "2.2434022426605225\n",
      "2.243401527404785\n",
      "2.243401050567627\n",
      "2.2434005737304688\n",
      "2.2434000968933105\n",
      "2.2433993816375732\n",
      "2.243398904800415\n",
      "2.2433981895446777\n",
      "2.2433977127075195\n",
      "2.2433969974517822\n",
      "2.243396520614624\n",
      "2.243396043777466\n",
      "2.2433953285217285\n",
      "2.2433948516845703\n",
      "2.243394374847412\n",
      "2.243393898010254\n",
      "2.2433931827545166\n",
      "2.2433927059173584\n",
      "2.243391990661621\n",
      "2.243391513824463\n",
      "2.2433910369873047\n",
      "2.2433903217315674\n",
      "2.243389844894409\n",
      "2.243389129638672\n",
      "2.2433886528015137\n",
      "2.2433881759643555\n",
      "2.243387222290039\n",
      "2.243386745452881\n",
      "2.2433862686157227\n",
      "2.2433855533599854\n",
      "2.243385076522827\n",
      "2.243384599685669\n",
      "2.2433841228485107\n",
      "2.2433834075927734\n",
      "2.243382692337036\n",
      "2.243382215499878\n",
      "2.2433817386627197\n",
      "2.2433810234069824\n",
      "2.243380546569824\n",
      "2.243380069732666\n",
      "2.2433793544769287\n",
      "2.2433788776397705\n",
      "2.2433784008026123\n",
      "2.243377447128296\n",
      "2.2433769702911377\n",
      "2.2433764934539795\n",
      "2.2433760166168213\n",
      "2.243375539779663\n",
      "2.243374824523926\n"
     ]
    }
   ],
   "source": [
    "# gradient descend\n",
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=numchars).float() # input to the network: one_hot encoding\n",
    "    logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilites for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None # set the gradients to zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    W.data += -1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "831af6c4-3469-4f03-8d1c-7ad49a2ff451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osprgetrumallymarlannavikh.\n",
      "ree.\n",
      "isnerse.\n",
      "ore.\n",
      "sarneve.\n",
      "ah.\n",
      "aim.\n",
      "enikavielah.\n",
      "sh.\n",
      "aia.\n"
     ]
    }
   ],
   "source": [
    "# Sample from the neutral net\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    out=[]\n",
    "    ix1 = 0\n",
    "    ix2 = torch.randint(1, 27, (1,), generator=g)\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=numchars).float()\n",
    "        logits = xenc.view(-1, 2*27) @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        \n",
    "        iy = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(ytos[iy])\n",
    "        if iy == 0: \n",
    "            break\n",
    "            \n",
    "        ix1 = ix2\n",
    "        ix2 = iy\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
